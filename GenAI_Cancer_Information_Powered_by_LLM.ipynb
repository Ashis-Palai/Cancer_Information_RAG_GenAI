{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "AGGL_JFf-49m"
      ],
      "authorship_tag": "ABX9TyPkmUkppupad/ZUDIWiyDgr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashis-Palai/Cancer_Information_RAG_GenAI/blob/main/GenAI_Cancer_Information_Powered_by_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA EXTRACTION:**\n",
        "\n"
      ],
      "metadata": {
        "id": "AGGL_JFf-49m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sources**\n",
        "\n",
        "* **Cervical , Breast & Oral Cancers:**\n",
        "\n",
        "\n",
        "> ```\n",
        "https://tmc.gov.in/ncg/docs/PDF/DraftGuidelines/Preventive/3_%20NCG_INDIA_Rev_Preventive%20Oncology_Primary_Care.pdf\n",
        "```\n",
        "\n",
        "\n",
        "* **Ovarian_Cancer:**\n",
        "\n",
        "> ```\n",
        "https://main.icmr.nic.in/sites/default/files/guidelines/Ovarian_Cancer.pdf\n",
        "```\n",
        "\n",
        "\n",
        "* **Generic Information About Cancer**\n",
        "\n",
        ">```\n",
        "https://www.mayoclinic.org/diseases-conditions/cancer/diagnosis-treatment/drc-20370594\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "* **Breast Cancer:**\n",
        "\n",
        ">```\n",
        "https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection.html\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ES25Box0--7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O \"https://raw.githubusercontent.com/Ashis-Palai/Cancer_Information_RAG_GenAI/main/helper.py\"\n",
        "!curl -O \"https://raw.githubusercontent.com/Ashis-Palai/Cancer_Information_RAG_GenAI/main/requirements.txt\""
      ],
      "metadata": {
        "id": "_-dW0Bbf4BEE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b59c7655-2530-425d-e6bf-4afe8d3a9f6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  3168  100  3168    0     0  10982      0 --:--:-- --:--:-- --:--:-- 10961\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   108  100   108    0     0    366      0 --:--:-- --:--:-- --:--:--   367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO5d1G4I8FNU",
        "outputId": "8c0df5a7-786a-40d9-de5f-768c50420958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain (from -r requirements.txt (line 1))\n",
            "  Downloading langchain-0.1.7-py3-none-any.whl (815 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.9/815.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-community (from -r requirements.txt (line 2))\n",
            "  Downloading langchain_community-0.0.20-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unstructured (from -r requirements.txt (line 3))\n",
            "  Downloading unstructured-0.12.4-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers (from -r requirements.txt (line 4))\n",
            "  Downloading sentence_transformers-2.3.1-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.1.0+cu121)\n",
            "Collecting llama-index (from -r requirements.txt (line 6))\n",
            "  Downloading llama_index-0.10.6-py3-none-any.whl (5.6 kB)\n",
            "Collecting langchain_google_genai (from -r requirements.txt (line 7))\n",
            "  Downloading langchain_google_genai-0.0.9-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (2.0.27)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain->-r requirements.txt (line 1))\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain->-r requirements.txt (line 1))\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-core<0.2,>=0.1.22 (from langchain->-r requirements.txt (line 1))\n",
            "  Downloading langchain_core-0.1.23-py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain->-r requirements.txt (line 1))\n",
            "  Downloading langsmith-0.0.92-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (8.2.3)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 3)) (5.2.0)\n",
            "Collecting filetype (from unstructured->-r requirements.txt (line 3))\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting python-magic (from unstructured->-r requirements.txt (line 3))\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 3)) (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 3)) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 3)) (0.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 3)) (4.12.3)\n",
            "Collecting emoji (from unstructured->-r requirements.txt (line 3))\n",
            "  Downloading emoji-2.10.1-py2.py3-none-any.whl (421 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-iso639 (from unstructured->-r requirements.txt (line 3))\n",
            "  Downloading python_iso639-2024.2.7-py3-none-any.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langdetect (from unstructured->-r requirements.txt (line 3))\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rapidfuzz (from unstructured->-r requirements.txt (line 3))\n",
            "  Downloading rapidfuzz-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff (from unstructured->-r requirements.txt (line 3))\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 3)) (4.9.0)\n",
            "Collecting unstructured-client>=0.15.1 (from unstructured->-r requirements.txt (line 3))\n",
            "  Downloading unstructured_client-0.18.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 3)) (1.14.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 4)) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 4)) (4.66.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 4)) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 4)) (1.11.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 4)) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 4)) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 4)) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (2.1.0)\n",
            "Collecting llama-index-agent-openai<0.2.0,>=0.1.0 (from llama-index->-r requirements.txt (line 6))\n",
            "  Downloading llama_index_agent_openai-0.1.1-py3-none-any.whl (12 kB)\n",
            "Collecting llama-index-core<0.11.0,>=0.10.0 (from llama-index->-r requirements.txt (line 6))\n",
            "  Downloading llama_index_core-0.10.6.post1-py3-none-any.whl (15.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-embeddings-openai<0.2.0,>=0.1.0 (from llama-index->-r requirements.txt (line 6))\n",
            "  Downloading llama_index_embeddings_openai-0.1.1-py3-none-any.whl (6.1 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index->-r requirements.txt (line 6))\n",
            "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-llms-openai<0.2.0,>=0.1.0 (from llama-index->-r requirements.txt (line 6))\n",
            "  Downloading llama_index_llms_openai-0.1.2-py3-none-any.whl (9.5 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.0 (from llama-index->-r requirements.txt (line 6))\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.1-py3-none-any.whl (6.0 kB)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.0 (from llama-index->-r requirements.txt (line 6))\n",
            "  Downloading llama_index_program_openai-0.1.2-py3-none-any.whl (4.3 kB)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.0 (from llama-index->-r requirements.txt (line 6))\n",
            "  Downloading llama_index_question_gen_openai-0.1.1-py3-none-any.whl (3.1 kB)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.0 (from llama-index->-r requirements.txt (line 6))\n",
            "  Downloading llama_index_readers_file-0.1.3-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: google-generativeai<0.4.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai->-r requirements.txt (line 7)) (0.3.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 1))\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 1))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain_google_genai->-r requirements.txt (line 7)) (0.4.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain_google_genai->-r requirements.txt (line 7)) (2.27.0)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain_google_genai->-r requirements.txt (line 7)) (2.11.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain_google_genai->-r requirements.txt (line 7)) (3.20.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.4.0->google-generativeai<0.4.0,>=0.3.1->langchain_google_genai->-r requirements.txt (line 7)) (1.23.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers->-r requirements.txt (line 4)) (23.2)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain->-r requirements.txt (line 1))\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.22->langchain->-r requirements.txt (line 1)) (3.7.1)\n",
            "Collecting langsmith<0.1,>=0.0.83 (from langchain->-r requirements.txt (line 1))\n",
            "  Downloading langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.0->llama-index->-r requirements.txt (line 6))\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.0->llama-index->-r requirements.txt (line 6))\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Collecting httpx (from llama-index-core<0.11.0,>=0.10.0->llama-index->-r requirements.txt (line 6))\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llamaindex-py-client>=0.1.12 (from llama-index-core<0.11.0,>=0.10.0->llama-index->-r requirements.txt (line 6))\n",
            "  Downloading llamaindex_py_client-0.1.13-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index->-r requirements.txt (line 6)) (1.6.0)\n",
            "Collecting openai>=1.1.0 (from llama-index-core<0.11.0,>=0.10.0->llama-index->-r requirements.txt (line 6))\n",
            "  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index->-r requirements.txt (line 6)) (1.5.3)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.0->llama-index->-r requirements.txt (line 6))\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bs4<0.0.3,>=0.0.2 (from llama-index-readers-file<0.2.0,>=0.1.0->llama-index->-r requirements.txt (line 6))\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Collecting pymupdf<2.0.0,>=1.23.21 (from llama-index-readers-file<0.2.0,>=0.1.0->llama-index->-r requirements.txt (line 6))\n",
            "  Downloading PyMuPDF-1.23.22-cp310-none-manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.0->llama-index->-r requirements.txt (line 6))\n",
            "  Downloading pypdf-4.0.1-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.0/284.0 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured->-r requirements.txt (line 3)) (2.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured->-r requirements.txt (line 3)) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured->-r requirements.txt (line 3)) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured->-r requirements.txt (line 3)) (2023.12.25)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain->-r requirements.txt (line 1)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain->-r requirements.txt (line 1)) (2.16.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 1)) (3.0.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers->-r requirements.txt (line 4)) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers->-r requirements.txt (line 4)) (0.4.2)\n",
            "Collecting dataclasses-json-speakeasy>=0.5.11 (from unstructured-client>=0.15.1->unstructured->-r requirements.txt (line 3))\n",
            "  Downloading dataclasses_json_speakeasy-0.5.11-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpath-python>=1.0.6 (from unstructured-client>=0.15.1->unstructured->-r requirements.txt (line 3))\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Collecting mypy-extensions>=1.0.0 (from unstructured-client>=0.15.1->unstructured->-r requirements.txt (line 3))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured->-r requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 5)) (2.1.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 4)) (3.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain->-r requirements.txt (line 1)) (1.2.0)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.0->llama-index->-r requirements.txt (line 6))\n",
            "  Downloading httpcore-1.0.3-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.0->llama-index->-r requirements.txt (line 6))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.0->llama-index->-r requirements.txt (line 6)) (1.7.0)\n",
            "Collecting PyMuPDFb==1.23.22 (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.0->llama-index->-r requirements.txt (line 6))\n",
            "  Downloading PyMuPDFb-1.23.22-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain_google_genai->-r requirements.txt (line 7)) (1.62.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain_google_genai->-r requirements.txt (line 7)) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain_google_genai->-r requirements.txt (line 7)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain_google_genai->-r requirements.txt (line 7)) (4.9)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.0->llama-index->-r requirements.txt (line 6)) (2023.4)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain_google_genai->-r requirements.txt (line 7)) (1.60.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain_google_genai->-r requirements.txt (line 7)) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai<0.4.0,>=0.3.1->langchain_google_genai->-r requirements.txt (line 7)) (0.5.1)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=bea30d72ddcc6508f8478468cafe52f6e1e633df13cb6dfac9f8ca94476d286f\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: filetype, dirtyjson, rapidfuzz, python-magic, python-iso639, pypdf, PyMuPDFb, mypy-extensions, marshmallow, langdetect, jsonpointer, jsonpath-python, h11, emoji, deprecated, backoff, typing-inspect, tiktoken, pymupdf, jsonpatch, httpcore, bs4, langsmith, httpx, dataclasses-json-speakeasy, dataclasses-json, unstructured-client, openai, llamaindex-py-client, langchain-core, unstructured, sentence-transformers, llama-index-legacy, llama-index-core, langchain-community, llama-index-readers-file, llama-index-llms-openai, llama-index-embeddings-openai, langchain, llama-index-multi-modal-llms-openai, llama-index-agent-openai, langchain_google_genai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyMuPDFb-1.23.22 backoff-2.2.1 bs4-0.0.2 dataclasses-json-0.6.4 dataclasses-json-speakeasy-0.5.11 deprecated-1.2.14 dirtyjson-1.0.8 emoji-2.10.1 filetype-1.2.0 h11-0.14.0 httpcore-1.0.3 httpx-0.26.0 jsonpatch-1.33 jsonpath-python-1.0.6 jsonpointer-2.4 langchain-0.1.7 langchain-community-0.0.20 langchain-core-0.1.23 langchain_google_genai-0.0.9 langdetect-1.0.9 langsmith-0.0.87 llama-index-0.10.6 llama-index-agent-openai-0.1.1 llama-index-core-0.10.6.post1 llama-index-embeddings-openai-0.1.1 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.2 llama-index-multi-modal-llms-openai-0.1.1 llama-index-program-openai-0.1.2 llama-index-question-gen-openai-0.1.1 llama-index-readers-file-0.1.3 llamaindex-py-client-0.1.13 marshmallow-3.20.2 mypy-extensions-1.0.0 openai-1.12.0 pymupdf-1.23.22 pypdf-4.0.1 python-iso639-2024.2.7 python-magic-0.4.27 rapidfuzz-3.6.1 sentence-transformers-2.3.1 tiktoken-0.6.0 typing-inspect-0.9.0 unstructured-0.12.4 unstructured-client-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_url = [ 'https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection.html',\n",
        "'https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection/american-cancer-society-recommendations-for-the-early-detection-of-breast-cancer.html',\n",
        "'https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection/mammograms.html',\n",
        "'https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection/breast-ultrasound.html',\n",
        "'https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection/breast-mri-scans.html',\n",
        "'https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection/breast-cancer-signs-and-symptoms.html',\n",
        "'https://tmc.gov.in/ncg/docs/PDF/DraftGuidelines/Preventive/3_%20NCG_INDIA_Rev_Preventive%20Oncology_Primary_Care.pdf',\n",
        "'https://main.icmr.nic.in/sites/default/files/guidelines/Ovarian_Cancer.pdf'\n",
        "            ]"
      ],
      "metadata": {
        "id": "UrUQZmsDquJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper import extract_headings_and_content , word_wrap\n",
        "for i, url in enumerate(all_url, start=1):\n",
        "    result_message = extract_headings_and_content(url, i)\n",
        "    print(result_message)"
      ],
      "metadata": {
        "id": "t41HJY5I4LgI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad820243-baf7-4f09-b8d8-f1c181b7aa3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction and saving successful for https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection.html. File saved as data/html_data/html_file_1.html\n",
            "Extraction and saving successful for https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection/american-cancer-society-recommendations-for-the-early-detection-of-breast-cancer.html. File saved as data/html_data/html_file_2.html\n",
            "Extraction and saving successful for https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection/mammograms.html. File saved as data/html_data/html_file_3.html\n",
            "Extraction and saving successful for https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection/breast-ultrasound.html. File saved as data/html_data/html_file_4.html\n",
            "Extraction and saving successful for https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection/breast-mri-scans.html. File saved as data/html_data/html_file_5.html\n",
            "Extraction and saving successful for https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection/breast-cancer-signs-and-symptoms.html. File saved as data/html_data/html_file_6.html\n",
            "Extraction and saving successful for https://tmc.gov.in/ncg/docs/PDF/DraftGuidelines/Preventive/3_%20NCG_INDIA_Rev_Preventive%20Oncology_Primary_Care.pdf. File saved as data/pdf_data/pdf_file_7.pdf\n",
            "Extraction and saving successful for https://main.icmr.nic.in/sites/default/files/guidelines/Ovarian_Cancer.pdf. File saved as data/pdf_data/pdf_file_8.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Transformation Using Langchain**"
      ],
      "metadata": {
        "id": "eO_38z9L82LS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader , UnstructuredHTMLLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter , SentenceTransformersTokenTextSplitter\n",
        "import glob"
      ],
      "metadata": {
        "id": "Xzc7Qj5oYBRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBcJ7kvoATv8",
        "outputId": "7d855218-46e9-4f89-d14d-20b56fa7f0e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (4.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "base_path = '/content/data'\n",
        "\n",
        "# List all HTML files\n",
        "html_files = glob.glob(f\"{base_path}/html*/*.html\")\n",
        "\n",
        "# List all PDF files\n",
        "pdf_files = glob.glob(f\"{base_path}/pdf*/*.pdf\")\n",
        "\n",
        "\n",
        "all_results = [PyPDFLoader(file).load() if file.endswith(\".pdf\") else UnstructuredHTMLLoader(file).load() for file in pdf_files + html_files]\n",
        "\n"
      ],
      "metadata": {
        "id": "4nCsp8cbGR7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_pages = sum([len(i) for i in all_results ])\n",
        "total_pages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMuVsRcKBeo7",
        "outputId": "c46a7d7b-3e96-4647-f50b-6f94a5a9cdca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "107"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_text_data = [j.page_content.strip() for i in all_results for j  in i]"
      ],
      "metadata": {
        "id": "aCheBKMHD6G-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_text_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRAeA1_eEk91",
        "outputId": "b3b73105-58c2-4e4c-f79d-6d6871a4da03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "107"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_text_data = [ i for i in all_text_data if i]"
      ],
      "metadata": {
        "id": "M0zj_oQpElBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_text_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OijspTiyExGI",
        "outputId": "bac972d4-7654-4cae-cbd5-ca464ee88d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splitter_1 =  RecursiveCharacterTextSplitter(\n",
        "    separators= ['\\n\\n\\n\\n\\n','\\n\\n\\n\\n','\\n\\n\\n','\\n\\n','\\n','.',',',' '],\n",
        "    chunk_size = 1000 ,chunk_overlap = 100\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "Arp8boOxvI_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splitter_2 = SentenceTransformersTokenTextSplitter(tokens_per_chunk=256,chunk_overlap=10)"
      ],
      "metadata": {
        "id": "yiuRFKkOzR2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splitted_data_1 = splitter_1.split_text('\\n'.join(all_text_data))\n",
        "len(splitted_data_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzY58-t8JmlE",
        "outputId": "d3766d54-9f4a-4d7e-9322-4fa208217e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "313"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splitted_data_2 = []\n",
        "for text in splitted_data_1:\n",
        "  splitted_data_2 += splitter_2.split_text(text)\n",
        "\n",
        "# splitted_data_2 = splitter_1.split_text('\\n'.join(splitted_data_1))\n",
        "len(splitted_data_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0aTQij4FJiu",
        "outputId": "3594a272-05a5-4132-c0de-2238e8a94e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "385"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splitted_data_2 = splitter_2.split_text('\\n'.join(data))\n"
      ],
      "metadata": {
        "id": "6wwx-qWLzyHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(splitted_data_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvzc0vlMyqVA",
        "outputId": "70b24904-7638-49e8-d6eb-2619ca428eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(splitted_data_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74PwShUOz2_i",
        "outputId": "933f3381-7c52-4bfe-920b-b1de9f774b7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splitted_data_1[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PYudNGo8yukF",
        "outputId": "084cc64a-77c3-4861-8f3a-f1573e28d71e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Extracted Information\\n\\nPatient Programs:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splitted_data_2[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "Om16llrQz8el",
        "outputId": "48852af1-c9da-4e03-c5c5-7702b6f8ea79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'extracted information patient programs : patient programs : free rides to treatment free lodging during treatment acs cares™ research we conduct : research tools : research we conduct : cancer facts & statistics acs screening guidelines cps - 3 : cancer prevention study - 3 research'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unstructured"
      ],
      "metadata": {
        "id": "_7Ensuz6JmnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
        "loader = UnstructuredHTMLLoader(\"/content/data/html_data/html_file_3.html\")\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "mf9uRhYhJmqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgxbY86bK5RZ",
        "outputId": "939f6b01-eeee-4cd8-c832-a132f651ef26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"Extracted Information\\n\\nPatient Programs:\\n\\nPatient Programs:\\n\\nFree Rides to Treatment\\n\\nFree Lodging During Treatment\\n\\nACS CARES™\\n\\nResearch We Conduct:\\n\\nResearch Tools:\\n\\nResearch We Conduct:\\n\\nCancer Facts & Statistics\\n\\nACS Screening Guidelines\\n\\nCPS-3: Cancer Prevention Study-3\\n\\nResearch Tools:\\n\\nCancer Atlas\\n\\nCancer Statistics Center\\n\\nGlossary for Nonscientists\\n\\nPatient Programs:\\n\\nPatient Programs:\\n\\nFree Rides to Treatment\\n\\nFree Lodging During Treatment\\n\\nACS CARES™\\n\\nResearch We Conduct:\\n\\nResearch Tools:\\n\\nResearch We Conduct:\\n\\nCancer Facts & Statistics\\n\\nACS Screening Guidelines\\n\\nCPS-3: Cancer Prevention Study-3\\n\\nResearch Tools:\\n\\nCancer Atlas\\n\\nCancer Statistics Center\\n\\nGlossary for Nonscientists\\n\\nContact Us:\\n\\nOnline Help:\\n\\nMammograms:\\n\\nGetting a mammogram: \\n\\nFind out what a mammogram is, why it's done, what doctors look for, and what it's like to get one.\\n\\nUnderstanding your results: \\n\\nDoctors use a standard system called the Breast Imaging Reporting and Data System (BI-RADS) to describe what they see on a mammogram. Learn how to understand your results, and what it means if your mammograms show dense breast tissue.\\n\\nMammograms in special circumstances: \\n\\nIf you have had breast cancer in the past, whether or not you need to keep getting mammograms might depend on the type of surgery you had.   If you have breast implants, you can and should get mammograms\\xa0as recommended. But you might need to have extra pictures taken so the doctor can see as much breast tissue as possible.\\n\\nAmerican Cancer Society Emails: Sign up to stay up-to-date with news, valuable information, and ways to get involved with the American Cancer Society.\\n\\nMore in Breast Cancer:\\n\\nHelp us end cancer as we know it, for everyone.:\\n\\nCancer information, answers, and hope. Available every minute of every day.:\\n\\nCancer Information: \\n Cancer Prevention & Detection \\n Understanding Cancer \\n Signs & Symptoms of Cancer \\n Cancer Treatment \\n ACS Research Highlights \\n Cancer Facts & Statistics \\n News and Stories \\n Glossary \\n For Health Care Professionals\\n\\nACS Fundraisers: \\n Making Strides Against Breast Cancer Walks \\n Relay For Life Events \\n American Cancer Society on Campus \\n Coaches vs. Cancer \\n Galas, Balls & Parties \\n Ways to Give \\n Memorial Giving \\n Planned Giving \\n Philanthropy \\n Donate a Car \\n Coupons That Give \\n Donate by Mail or Phone\\n\\nAbout ACS: \\n Contact Us \\n ACS in Your Community \\n Employment \\n Information for Suppliers \\n Report Fraud or Abuse \\n Sign Up for Email \\n Our Research \\n Cancer Action Network \\n Global Health \\n Policies \\n Our Volunteers\\n\\nAbout ACS Programs & Services: \\n Lodging During Treatment \\n Rides To Treatment \\n Breast Cancer Support \\n Hair Loss and Mastectomy Products \\n Connecting Cancer Survivors\\n\\nMore ACS Sites: \\n Bookstore \\n Cancer Atlas \\n Cancer Statistics Center \\n ACS News Room \\n American Cancer Society Roundtables \\n Volunteer Community\", metadata={'source': '/content/data/html_data/html_file_3.html'})]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T--ZJP3BK5sl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}