{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "AGGL_JFf-49m"
      ],
      "authorship_tag": "ABX9TyN6yL8V9EESnp5RjIqJbRlf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashis-Palai/Cancer_Information_RAG_GenAI/blob/main/GenAI_Cancer_Information_Powered_by_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA EXTRACTION:**\n",
        "\n"
      ],
      "metadata": {
        "id": "AGGL_JFf-49m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sources**\n",
        "\n",
        "* **Cervical , Breast & Oral Cancers:**\n",
        "\n",
        "\n",
        "> ```\n",
        "https://tmc.gov.in/ncg/docs/PDF/DraftGuidelines/Preventive/3_%20NCG_INDIA_Rev_Preventive%20Oncology_Primary_Care.pdf\n",
        "```\n",
        "\n",
        "\n",
        "* **Ovarian_Cancer:**\n",
        "\n",
        "> ```\n",
        "https://main.icmr.nic.in/sites/default/files/guidelines/Ovarian_Cancer.pdf\n",
        "```\n",
        "\n",
        "\n",
        "* **Generic Information About Cancer**\n",
        "\n",
        ">```\n",
        "https://www.mayoclinic.org/diseases-conditions/cancer/diagnosis-treatment/drc-20370594\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "* **Breast Cancer:**\n",
        "\n",
        ">```\n",
        "https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection.html\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ES25Box0--7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O \"https://raw.githubusercontent.com/Ashis-Palai/Cancer_Information_RAG_GenAI/main/helper.py\"\n",
        "!curl -O \"https://raw.githubusercontent.com/Ashis-Palai/Cancer_Information_RAG_GenAI/main/requirements.txt\""
      ],
      "metadata": {
        "id": "_-dW0Bbf4BEE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c54d79dd-f809-4e6a-dab3-72b7cfb2eaf1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  3168  100  3168    0     0  17810      0 --:--:-- --:--:-- --:--:-- 17898\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   114  100   114    0     0    475      0 --:--:-- --:--:-- --:--:--   475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO5d1G4I8FNU",
        "outputId": "8c08ee58-ccfc-488a-bc81-826447a98376"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain (from -r requirements.txt (line 1))\n",
            "  Downloading langchain-0.1.7-py3-none-any.whl (815 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.9/815.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-community (from -r requirements.txt (line 2))\n",
            "  Downloading langchain_community-0.0.20-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unstructured (from -r requirements.txt (line 3))\n",
            "  Downloading unstructured-0.12.4-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers (from -r requirements.txt (line 4))\n",
            "  Downloading sentence_transformers-2.3.1-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.1.0+cu121)\n",
            "Collecting llama-index (from -r requirements.txt (line 6))\n",
            "  Downloading llama_index-0.10.6-py3-none-any.whl (5.6 kB)\n",
            "Collecting langchain_google_genai (from -r requirements.txt (line 7))\n",
            "  Downloading langchain_google_genai-0.0.9-py3-none-any.whl (17 kB)\n",
            "Collecting pypdf (from -r requirements.txt (line 8))\n",
            "  Downloading pypdf-4.0.2-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.0/284.0 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (2.0.27)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain->-r requirements.txt (line 1))\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain->-r requirements.txt (line 1))\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-core<0.2,>=0.1.22 (from langchain->-r requirements.txt (line 1))\n",
            "  Downloading langchain_core-0.1.23-py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain->-r requirements.txt (line 1))\n",
            "  Downloading langsmith-0.0.92-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (8.2.3)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 3)) (5.2.0)\n",
            "Collecting filetype (from unstructured->-r requirements.txt (line 3))\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting python-magic (from unstructured->-r requirements.txt (line 3))\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 3)) (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 3)) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 3)) (0.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 3)) (4.12.3)\n",
            "Collecting emoji (from unstructured->-r requirements.txt (line 3))\n",
            "  Downloading emoji-2.10.1-py2.py3-none-any.whl (421 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-iso639 (from unstructured->-r requirements.txt (line 3))\n",
            "  Downloading python_iso639-2024.2.7-py3-none-any.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langdetect (from unstructured->-r requirements.txt (line 3))\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rapidfuzz (from unstructured->-r requirements.txt (line 3))\n",
            "  Downloading rapidfuzz-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff (from unstructured->-r requirements.txt (line 3))\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 3)) (4.9.0)\n",
            "Collecting unstructured-client>=0.15.1 (from unstructured->-r requirements.txt (line 3))\n",
            "  Downloading unstructured_client-0.18.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured->-r requirements.txt (line 3)) (1.14.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 4)) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 4)) (4.66.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 4)) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 4)) (1.11.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 4)) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 4)) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r requirements.txt (line 4)) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (2.1.0)\n",
            "Collecting llama-index-agent-openai<0.2.0,>=0.1.0 (from llama-index->-r requirements.txt (line 6))\n",
            "  Downloading llama_index_agent_openai-0.1.1-py3-none-any.whl (12 kB)\n",
            "Collecting llama-index-core<0.11.0,>=0.10.0 (from llama-index->-r requirements.txt (line 6))\n",
            "  Downloading llama_index_core-0.10.6.post1-py3-none-any.whl (15.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-embeddings-openai<0.2.0,>=0.1.0 (from llama-index->-r requirements.txt (line 6))\n",
            "  Downloading llama_index_embeddings_openai-0.1.1-py3-none-any.whl (6.1 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index->-r requirements.txt (line 6))\n",
            "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-llms-openai<0.2.0,>=0.1.0 (from llama-index->-r requirements.txt (line 6))\n",
            "  Downloading llama_index_llms_openai-0.1.2-py3-none-any.whl (9.5 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.0 (from llama-index->-r requirements.txt (line 6))\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.1-py3-none-any.whl (6.0 kB)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.0 (from llama-index->-r requirements.txt (line 6))\n",
            "  Downloading llama_index_program_openai-0.1.2-py3-none-any.whl (4.3 kB)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.0 (from llama-index->-r requirements.txt (line 6))\n",
            "  Downloading llama_index_question_gen_openai-0.1.1-py3-none-any.whl (3.1 kB)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.0 (from llama-index->-r requirements.txt (line 6))\n",
            "  Downloading llama_index_readers_file-0.1.3-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: google-generativeai<0.4.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai->-r requirements.txt (line 7)) (0.3.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1)) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 1))\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 1))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain_google_genai->-r requirements.txt (line 7)) (0.4.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain_google_genai->-r requirements.txt (line 7)) (2.27.0)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain_google_genai->-r requirements.txt (line 7)) (2.11.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.4.0,>=0.3.1->langchain_google_genai->-r requirements.txt (line 7)) (3.20.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.4.0->google-generativeai<0.4.0,>=0.3.1->langchain_google_genai->-r requirements.txt (line 7)) (1.23.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers->-r requirements.txt (line 4)) (23.2)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain->-r requirements.txt (line 1))\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.22->langchain->-r requirements.txt (line 1)) (3.7.1)\n",
            "Collecting langsmith<0.1,>=0.0.83 (from langchain->-r requirements.txt (line 1))\n",
            "  Downloading langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.0->llama-index->-r requirements.txt (line 6))\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.0->llama-index->-r requirements.txt (line 6))\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Collecting httpx (from llama-index-core<0.11.0,>=0.10.0->llama-index->-r requirements.txt (line 6))\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llamaindex-py-client>=0.1.12 (from llama-index-core<0.11.0,>=0.10.0->llama-index->-r requirements.txt (line 6))\n",
            "  Downloading llamaindex_py_client-0.1.13-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index->-r requirements.txt (line 6)) (1.6.0)\n",
            "Collecting openai>=1.1.0 (from llama-index-core<0.11.0,>=0.10.0->llama-index->-r requirements.txt (line 6))\n",
            "  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index->-r requirements.txt (line 6)) (1.5.3)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.0->llama-index->-r requirements.txt (line 6))\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bs4<0.0.3,>=0.0.2 (from llama-index-readers-file<0.2.0,>=0.1.0->llama-index->-r requirements.txt (line 6))\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Collecting pymupdf<2.0.0,>=1.23.21 (from llama-index-readers-file<0.2.0,>=0.1.0->llama-index->-r requirements.txt (line 6))\n",
            "  Downloading PyMuPDF-1.23.23-cp310-none-manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured->-r requirements.txt (line 3)) (2.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured->-r requirements.txt (line 3)) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured->-r requirements.txt (line 3)) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured->-r requirements.txt (line 3)) (2023.12.25)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain->-r requirements.txt (line 1)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain->-r requirements.txt (line 1)) (2.16.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 1)) (3.0.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers->-r requirements.txt (line 4)) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers->-r requirements.txt (line 4)) (0.4.2)\n",
            "Collecting dataclasses-json-speakeasy>=0.5.11 (from unstructured-client>=0.15.1->unstructured->-r requirements.txt (line 3))\n",
            "  Downloading dataclasses_json_speakeasy-0.5.11-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpath-python>=1.0.6 (from unstructured-client>=0.15.1->unstructured->-r requirements.txt (line 3))\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Collecting mypy-extensions>=1.0.0 (from unstructured-client>=0.15.1->unstructured->-r requirements.txt (line 3))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured->-r requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 5)) (2.1.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 4)) (3.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain->-r requirements.txt (line 1)) (1.2.0)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.0->llama-index->-r requirements.txt (line 6))\n",
            "  Downloading httpcore-1.0.3-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.0->llama-index->-r requirements.txt (line 6))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.0->llama-index->-r requirements.txt (line 6)) (1.7.0)\n",
            "Collecting PyMuPDFb==1.23.22 (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.0->llama-index->-r requirements.txt (line 6))\n",
            "  Downloading PyMuPDFb-1.23.22-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain_google_genai->-r requirements.txt (line 7)) (1.62.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain_google_genai->-r requirements.txt (line 7)) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain_google_genai->-r requirements.txt (line 7)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain_google_genai->-r requirements.txt (line 7)) (4.9)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.0->llama-index->-r requirements.txt (line 6)) (2023.4)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain_google_genai->-r requirements.txt (line 7)) (1.60.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain_google_genai->-r requirements.txt (line 7)) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai<0.4.0,>=0.3.1->langchain_google_genai->-r requirements.txt (line 7)) (0.5.1)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=97e8bc8bdc04544b715c76115a58a00ba4b420b8001a814bbf4fb69fb3ca0118\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: filetype, dirtyjson, rapidfuzz, python-magic, python-iso639, pypdf, PyMuPDFb, mypy-extensions, marshmallow, langdetect, jsonpointer, jsonpath-python, h11, emoji, deprecated, backoff, typing-inspect, tiktoken, pymupdf, jsonpatch, httpcore, bs4, langsmith, httpx, dataclasses-json-speakeasy, dataclasses-json, unstructured-client, openai, llamaindex-py-client, langchain-core, unstructured, sentence-transformers, llama-index-legacy, llama-index-core, langchain-community, llama-index-readers-file, llama-index-llms-openai, llama-index-embeddings-openai, langchain, llama-index-multi-modal-llms-openai, llama-index-agent-openai, langchain_google_genai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyMuPDFb-1.23.22 backoff-2.2.1 bs4-0.0.2 dataclasses-json-0.6.4 dataclasses-json-speakeasy-0.5.11 deprecated-1.2.14 dirtyjson-1.0.8 emoji-2.10.1 filetype-1.2.0 h11-0.14.0 httpcore-1.0.3 httpx-0.26.0 jsonpatch-1.33 jsonpath-python-1.0.6 jsonpointer-2.4 langchain-0.1.7 langchain-community-0.0.20 langchain-core-0.1.23 langchain_google_genai-0.0.9 langdetect-1.0.9 langsmith-0.0.87 llama-index-0.10.6 llama-index-agent-openai-0.1.1 llama-index-core-0.10.6.post1 llama-index-embeddings-openai-0.1.1 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.2 llama-index-multi-modal-llms-openai-0.1.1 llama-index-program-openai-0.1.2 llama-index-question-gen-openai-0.1.1 llama-index-readers-file-0.1.3 llamaindex-py-client-0.1.13 marshmallow-3.20.2 mypy-extensions-1.0.0 openai-1.12.0 pymupdf-1.23.23 pypdf-4.0.2 python-iso639-2024.2.7 python-magic-0.4.27 rapidfuzz-3.6.1 sentence-transformers-2.3.1 tiktoken-0.6.0 typing-inspect-0.9.0 unstructured-0.12.4 unstructured-client-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_url = [ 'https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection.html',\n",
        "'https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection/american-cancer-society-recommendations-for-the-early-detection-of-breast-cancer.html',\n",
        "'https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection/mammograms.html',\n",
        "'https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection/breast-ultrasound.html',\n",
        "'https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection/breast-mri-scans.html',\n",
        "'https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection/breast-cancer-signs-and-symptoms.html',\n",
        "'https://tmc.gov.in/ncg/docs/PDF/DraftGuidelines/Preventive/3_%20NCG_INDIA_Rev_Preventive%20Oncology_Primary_Care.pdf',\n",
        "'https://main.icmr.nic.in/sites/default/files/guidelines/Ovarian_Cancer.pdf'\n",
        "            ]"
      ],
      "metadata": {
        "id": "UrUQZmsDquJU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper import extract_headings_and_content , word_wrap\n",
        "for i, url in enumerate(all_url, start=1):\n",
        "    result_message = extract_headings_and_content(url, i)\n",
        "    print(result_message)"
      ],
      "metadata": {
        "id": "t41HJY5I4LgI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f63ae563-76ea-4f84-f01f-9938a21ca300"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction and saving successful for https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection.html. File saved as data/html_data/html_file_1.html\n",
            "Extraction and saving successful for https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection/american-cancer-society-recommendations-for-the-early-detection-of-breast-cancer.html. File saved as data/html_data/html_file_2.html\n",
            "Extraction and saving successful for https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection/mammograms.html. File saved as data/html_data/html_file_3.html\n",
            "Extraction and saving successful for https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection/breast-ultrasound.html. File saved as data/html_data/html_file_4.html\n",
            "Extraction and saving successful for https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection/breast-mri-scans.html. File saved as data/html_data/html_file_5.html\n",
            "Extraction and saving successful for https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection/breast-cancer-signs-and-symptoms.html. File saved as data/html_data/html_file_6.html\n",
            "Extraction and saving successful for https://tmc.gov.in/ncg/docs/PDF/DraftGuidelines/Preventive/3_%20NCG_INDIA_Rev_Preventive%20Oncology_Primary_Care.pdf. File saved as data/pdf_data/pdf_file_7.pdf\n",
            "Extraction and saving successful for https://main.icmr.nic.in/sites/default/files/guidelines/Ovarian_Cancer.pdf. File saved as data/pdf_data/pdf_file_8.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA TRANSFORMATION USING LANGCHAIN**"
      ],
      "metadata": {
        "id": "eO_38z9L82LS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader , UnstructuredHTMLLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter , SentenceTransformersTokenTextSplitter\n",
        "import glob"
      ],
      "metadata": {
        "id": "Xzc7Qj5oYBRL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "base_path = '/content/data'\n",
        "\n",
        "# List all HTML files\n",
        "html_files = glob.glob(f\"{base_path}/html*/*.html\")\n",
        "\n",
        "# List all PDF files\n",
        "pdf_files = glob.glob(f\"{base_path}/pdf*/*.pdf\")\n",
        "\n",
        "\n",
        "all_results = [PyPDFLoader(file).load() if file.endswith(\".pdf\") else UnstructuredHTMLLoader(file).load() for file in pdf_files + html_files]\n",
        "\n"
      ],
      "metadata": {
        "id": "4nCsp8cbGR7V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_pages = sum([len(i) for i in all_results ])\n",
        "total_pages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMuVsRcKBeo7",
        "outputId": "249865f9-51d8-4023-c027-3593f3005856"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "107"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_text_data = [j.page_content.strip() for i in all_results for j  in i]"
      ],
      "metadata": {
        "id": "aCheBKMHD6G-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_text_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRAeA1_eEk91",
        "outputId": "495f027a-2372-4e0c-e32c-84fa01eeeaab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "107"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_text_data = [ i for i in all_text_data if i] # To exclude the blank pages"
      ],
      "metadata": {
        "id": "M0zj_oQpElBc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_text_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OijspTiyExGI",
        "outputId": "ab8931e2-ca2b-404a-b47d-6f997a41162c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splitter_1 =  RecursiveCharacterTextSplitter(\n",
        "    separators= ['\\n\\n\\n\\n\\n','\\n\\n\\n\\n','\\n\\n\\n','\\n\\n','\\n','.',',',' '],\n",
        "    chunk_size = 1000 ,chunk_overlap = 100)\n",
        "\n",
        "splitter_2 = SentenceTransformersTokenTextSplitter(tokens_per_chunk=256,chunk_overlap=10)"
      ],
      "metadata": {
        "id": "Arp8boOxvI_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefinal_data = splitter_1.split_text('\\n'.join(all_text_data))\n",
        "len(prefinal_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzY58-t8JmlE",
        "outputId": "c88c67ca-7d9e-4b63-c12b-985ccd55a31e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "313"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = []\n",
        "[final_data.extend(splitter_2.split_text(text)) for text in prefinal_data]\n",
        "\n",
        "len(final_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0aTQij4FJiu",
        "outputId": "027cff33-5594-45c9-f62d-198e34199068"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "385"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prefinal_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "PYudNGo8yukF",
        "outputId": "cc35255b-eef3-4576-c0e5-208bb9995bbb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Coordinated by:\\nDivision of Non Communicable Diseases\\nIndian Council of Medical Research  \\nAnsari Nagar, New Delhi – 110029\\n2019CONSENSUS DOCUMENT FOR\\nMANAGEMENT OF\\nEPITHELIAL OVARIAN CANCER\\nPrepared as an outcome of ICMR Subcommittee on\\nEpithelial Ovarian Cancer\\nProf. Balram Bhargava  \\nSecretary,  \\nDepartment of Health Research  \\nand Director General, ICMR\\nPublished in 2019\\nHead (Publication & Information) : Dr. Neeraj Tandon\\nCompiled & Edited by: Dr. Hemant Tongaonkar & Dr. Tanvir Kaur\\nProduction Controller : Mr. JN Mathur \\nPublished by the Division of Publication and Information on behalf of the Secretary DHR & DG, ICMR,  \\nNew Delhi. \\nDesigned & Printed at M/s Royal Offset Printers, A-89/1, Naraina Industrial Area, Phase-I, New Delhi-110028  \\nMobile: 9811622258Disclaimer\\nThis consensus document represents the current thinking of experts on the topic based on available \\nevidence. This has been developed by national experts in the field and does not in any way bind'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "Om16llrQz8el",
        "outputId": "c77f2a1e-0959-471e-c235-c7b765b9e1f4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'coordinated by : division of non communicable diseases indian council of medical research ansari nagar, new delhi – 110029 2019consensus document for management of epithelial ovarian cancer prepared as an outcome of icmr subcommittee on epithelial ovarian cancer prof. balram bhargava secretary, department of health research and director general, icmr published in 2019 head ( publication & information ) : dr. neeraj tandon compiled & edited by : dr. hemant tongaonkar & dr. tanvir kaur production controller : mr. jn mathur published by the division of publication and information on behalf of the secretary dhr & dg, icmr, new delhi. designed & printed at m / s royal offset printers, a - 89 / 1, naraina industrial area, phase - i, new delhi - 110028 mobile : 9811622258disclaimer this consensus document represents the current thinking of experts on the topic based on available evidence. this has been developed by national experts in the field and does not in any way bind'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA LOADING**"
      ],
      "metadata": {
        "id": "MY9-TLHYaqS5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TWHlzscqaZBn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}